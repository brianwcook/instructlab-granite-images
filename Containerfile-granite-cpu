FROM registry.access.redhat.com/ubi9:9.4-1214.1726694543 AS env-build

WORKDIR /srv

ARG MODEL_DOWNLOAD_URL


# install build tools and clone and compile llama.cpp
RUN dnf -y update && dnf install -y git make automake gcc gcc-c++ llvm-toolset wget

RUN git clone https://github.com/ggerganov/llama.cpp.git \
  && cd llama.cpp \
  && make -j CC=clang-17 CXX=clang++-17


RUN wget ${MODEL_DOWNLOAD_URL} -P /models

# Runtime image
FROM registry.access.redhat.com/ubi9-minimal:9.4-1227.1726694542 AS env-deploy
ARG MODEL_FILENAME
RUN microdnf install shadow-utils
ENV LD_LIBRARY_PATH=/usr/local/lib

COPY --from=0 /usr/lib64/libomp.so ${LD_LIBRARY_PATH}/libomp.so

# copy llama.cpp binaries
COPY --from=0 /srv/llama.cpp/llama-cli /usr/local/bin/llama-cli
COPY --from=0 /srv/llama.cpp/llama-server /usr/local/bin/llama-server
COPY --from=0 /models/${MODEL_FILENAME} /models/${MODEL_FILENAME} 

ENV MODEL_PATH=/models/${MODEL_FILENAME}
EXPOSE 8080

# copy and set entrypoint script
COPY docker-entrypoint.sh /home/llama/docker-entrypoint.sh

COPY granite-license /licenses/granite-license
COPY llama-cpp-license /licenses/llama-cpp-license

RUN ["chmod", "+x", "/home/llama/docker-entrypoint.sh"]

RUN useradd --system --create-home llama

USER llama

WORKDIR /home/llama

ENTRYPOINT [ "/home/llama/docker-entrypoint.sh" ]